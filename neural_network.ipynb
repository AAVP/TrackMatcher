{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentiment_analysis.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPr5gbl2apw4xHxEbXYy4kK"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1ZPgFYiuEJbU","colab_type":"text"},"source":["# Sentiment Analysis for TrackMatcher"]},{"cell_type":"markdown","metadata":{"id":"FjcooxNsEu80","colab_type":"text"},"source":["This notebook is intended to run a model which can predict the emotion of a given track through its lyrics, using the library TensorFlow 2.0 in order to create the Deep Learning process. The model will be finally used in a Data Science Python project."]},{"cell_type":"markdown","metadata":{"id":"42upF5GxFplV","colab_type":"text"},"source":["First of all, we need to import the libraries:"]},{"cell_type":"code","metadata":{"id":"0POhnUvMENtx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600038238731,"user_tz":180,"elapsed":896,"user":{"displayName":"Alexander Valenzuela","photoUrl":"https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg","userId":"10143828526109492816"}}},"source":["import json\n","import csv\n","import os\n","import numpy as np\n","import tensorflow as tf\n","from google.colab import files\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import load_model"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CoOWf14NGHeD","colab_type":"text"},"source":["The next step is loading the parameters of the model which are stored in a json file named `parameters.json`"]},{"cell_type":"code","metadata":{"id":"Oy-jhhOnGEYg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600038239955,"user_tz":180,"elapsed":606,"user":{"displayName":"Alexander Valenzuela","photoUrl":"https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg","userId":"10143828526109492816"}}},"source":["with open('parameters.json', 'r') as json_file:\n","    pm = json.load(json_file)    "],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g4vabJZtHKHr","colab_type":"text"},"source":["The first part of a training model is loading the data."]},{"cell_type":"code","metadata":{"id":"wUqke9eQHKog","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600038241700,"user_tz":180,"elapsed":758,"user":{"displayName":"Alexander Valenzuela","photoUrl":"https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg","userId":"10143828526109492816"}}},"source":["training_lyrics = []  # Here will be stored the lyrics data\n","training_emotions = []  # Here will be stored the emotions data\n","testing_lyrics = []\n","testing_emotions = []\n","\n","# Here will be stored every type of emotiom\n","labels = [\"Anger\", \"Joy\", \"Sad\", \"Disgusting\", \"Fear\", \"Suprise\"]\n","\n","training_data_path = os.path.join('data', 'Training_lyrics.csv')\n","testing_data_path = os.path.join('data', 'Testing_lyrics.csv')\n","\n","\n","def loading_data(lyrics_list, emotions_list, path):\n","    with open(path, 'r', encoding='utf-8') as file:\n","        dataset = csv.reader(file)\n","        next(dataset)  # We skip the header of the file\n","\n","        for track in dataset:\n","            lyrics_list.append(track[0].capitalize())\n","            emotions_list.append(track[3].capitalize())\n","\n","\n","# We need to numerize the emotions\n","def numerize_emotions(emotions_dataset):\n","    for i in range(len(emotions_dataset)):\n","        for j in range(len(labels)):\n","            if emotions_dataset[i] == labels[j]:\n","                emotions_dataset[i] = j\n","\n","\n","loading_data(training_lyrics, training_emotions, training_data_path)\n","loading_data(testing_lyrics, testing_emotions, testing_data_path)\n","numerize_emotions(training_emotions)\n","numerize_emotions(testing_emotions)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AsqEvcorH7qX","colab_type":"text"},"source":["Once the data is stored in the code, we need to convert the data, which are fragments of lyrics, into numbers because the Deep Learning process only can work with number and vector arrays. This process is known as \"Tokenization\". Fortunately, `tensorflow` provides a `Tokenizer` class which has all the methods needed to tokenize our data. Moreover, the `numpy` library will help us convert the numbers into vector arrays."]},{"cell_type":"code","metadata":{"id":"--Pi1WVFH5iR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600038243957,"user_tz":180,"elapsed":832,"user":{"displayName":"Alexander Valenzuela","photoUrl":"https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg","userId":"10143828526109492816"}}},"source":["# Tokenization process\n","tokenizer = Tokenizer(num_words=pm[\"num_words\"], oov_token=pm[\"oov_tok\"])\n","tokenizer.fit_on_texts(training_lyrics)  # Words are fitted on the tokenizer\n","word_index = tokenizer.word_index  # Words are represented by index\n","\n","vocab_size = len(word_index) + 1  # The size of the vocabulary\n","\n","training_lyrics = tokenizer.texts_to_sequences(training_lyrics)\n","training_lyrics = pad_sequences(\n","    training_lyrics,\n","    maxlen=pm[\"max_length\"],\n","    padding=pm[\"padding_type\"],\n","    truncating=pm[\"trunc_type\"]\n",")\n","\n","testing_lyrics = tokenizer.texts_to_sequences(testing_lyrics)\n","testing_lyrics = pad_sequences(\n","    testing_lyrics,\n","    maxlen=pm[\"max_length\"],\n","    padding=pm[\"padding_type\"],\n","    truncating=pm[\"trunc_type\"]\n",")\n","\n","training_emotions = to_categorical(training_emotions, len(labels))\n","testing_emotions = to_categorical(testing_emotions, len(labels))\n","\n","\n","# Transforming the tokenized data in numpy arrays\n","training_lyrics = np.array(training_lyrics)\n","training_emotions = np.array(training_emotions)\n","testing_lyrics = np.array(testing_lyrics)\n","testing_emotions = np.array(testing_emotions)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wgvgy2-cK5Oo","colab_type":"text"},"source":["Now that the tokenization is done, let's create the model. the `tensorflow` library provides us a `Sequential` class which is used to build Neural Networks (NN). Each layer of our NN system has to be in the correct order, so first we need to create an `Embedding` layer in order to \"vectorize\" each sentense according to the similarity or difference of each input. For more info about how Neural Networks works, there are many information through Internet.\n","\n","Next, the output of this layer will be passed to `LSTM` layers, who will use the information and, in a recurrent loop the model will be trained. Finally, according to the result of each input, the `Dense` layers will help us define the result of the predictions."]},{"cell_type":"code","metadata":{"id":"Sz2jKX81K4Ng","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600038247747,"user_tz":180,"elapsed":1087,"user":{"displayName":"Alexander Valenzuela","photoUrl":"https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg","userId":"10143828526109492816"}}},"source":["# Generation of the Recurrent Neural Network (RNN)\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(input_dim=vocab_size,\n","                              input_length=pm[\"max_length\"],\n","                              output_dim=pm[\"embedding_dim\"]),\n","    tf.keras.layers.Dropout(0.3),\n","    tf.keras.layers.LSTM(pm[\"embedding_dim\"],\n","                         return_sequences=True,\n","                         dropout=0.3,\n","                         recurrent_dropout=0.2),\n","    tf.keras.layers.LSTM(pm[\"embedding_dim\"],\n","                         dropout=0.3,\n","                         recurrent_dropout=0.2),\n","    tf.keras.layers.Dense(len(labels), activation=\"softmax\")\n","])\n","\n","model.compile(\n","    loss=\"categorical_crossentropy\",\n","    optimizer=\"adam\",\n","    metrics=['accuracy']\n",")"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eDzqLnwzNLyw","colab_type":"text"},"source":["The last step of the training process is ... training the model."]},{"cell_type":"code","metadata":{"id":"Dvt840a4NE9l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":731},"executionInfo":{"status":"ok","timestamp":1600040853349,"user_tz":180,"elapsed":271754,"user":{"displayName":"Alexander Valenzuela","photoUrl":"https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg","userId":"10143828526109492816"}},"outputId":"d44a9201-ec7d-43c3-9402-d4c98de44262"},"source":["model.fit(\n","    training_lyrics,\n","    training_emotions,\n","    epochs=pm[\"num_epochs\"],\n","    batch_size=32,\n","    verbose=2\n",")\n","results = model.evaluate(testing_lyrics, testing_emotions)\n","print(results)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","158/158 - 127s - loss: 1.5894 - accuracy: 0.3075\n","Epoch 2/20\n","158/158 - 127s - loss: 1.5410 - accuracy: 0.3529\n","Epoch 3/20\n","158/158 - 128s - loss: 1.4087 - accuracy: 0.4624\n","Epoch 4/20\n","158/158 - 127s - loss: 1.2761 - accuracy: 0.5202\n","Epoch 5/20\n","158/158 - 127s - loss: 1.1599 - accuracy: 0.5677\n","Epoch 6/20\n","158/158 - 127s - loss: 1.0608 - accuracy: 0.6107\n","Epoch 7/20\n","158/158 - 127s - loss: 0.9354 - accuracy: 0.6570\n","Epoch 8/20\n","158/158 - 128s - loss: 0.8378 - accuracy: 0.6962\n","Epoch 9/20\n","158/158 - 129s - loss: 0.7515 - accuracy: 0.7339\n","Epoch 10/20\n","158/158 - 128s - loss: 0.6781 - accuracy: 0.7564\n","Epoch 11/20\n","158/158 - 127s - loss: 0.7656 - accuracy: 0.7297\n","Epoch 12/20\n","158/158 - 127s - loss: 0.6391 - accuracy: 0.7717\n","Epoch 13/20\n","158/158 - 129s - loss: 0.5628 - accuracy: 0.8083\n","Epoch 14/20\n","158/158 - 129s - loss: 0.5061 - accuracy: 0.8356\n","Epoch 15/20\n","158/158 - 128s - loss: 0.4537 - accuracy: 0.8529\n","Epoch 16/20\n","158/158 - 129s - loss: 0.4011 - accuracy: 0.8723\n","Epoch 17/20\n","158/158 - 130s - loss: 0.3590 - accuracy: 0.8830\n","Epoch 18/20\n","158/158 - 135s - loss: 0.3274 - accuracy: 0.8984\n","Epoch 19/20\n","158/158 - 130s - loss: 0.2917 - accuracy: 0.9137\n","Epoch 20/20\n","158/158 - 131s - loss: 0.2725 - accuracy: 0.9135\n","95/95 [==============================] - 12s 124ms/step - loss: 0.1628 - accuracy: 0.9555\n","[0.16278034448623657, 0.9554669260978699]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FR-LK7cZNhIz","colab_type":"text"},"source":["¡We have reached **95.54%** of accuracy!\n","\n","The following code is written in order to store in the local machine the fitted model"]},{"cell_type":"code","metadata":{"id":"w4jVZ6uyQ5-7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600041475149,"user_tz":180,"elapsed":725,"user":{"displayName":"Alexander Valenzuela","photoUrl":"https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg","userId":"10143828526109492816"}}},"source":["model.save('model.h5')"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5GkPUjJsNnZD","colab_type":"text"},"source":["Now, once the training and testing process are done, we can predict emotions with new information."]},{"cell_type":"code","metadata":{"id":"BxqcN7NbNgdF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600041505420,"user_tz":180,"elapsed":1778,"user":{"displayName":"Alexander Valenzuela","photoUrl":"https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg","userId":"10143828526109492816"}},"outputId":"4663b332-6dcc-4c54-e5cd-75b572b6438d"},"source":["model = load_model('model.h5')\n","\n","phrase = [\"Treasure, that is what you are\\nHoney, you're my golden star\"]\n","sequence = tokenizer.texts_to_sequences(phrase)\n","padded = pad_sequences(sequence,\n","                       maxlen=pm[\"max_length\"],\n","                       padding=pm[\"padding_type\"],\n","                       truncating=pm[\"trunc_type\"])\n","print(model.predict(padded))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[[1.3528788e-03 8.8281947e-01 1.2887026e-03 6.6673924e-04 1.0548627e-03\n","  1.1281747e-01]]\n"],"name":"stdout"}]}]}