{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZPgFYiuEJbU"
   },
   "source": [
    "# Sentiment Analysis for TrackMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FjcooxNsEu80"
   },
   "source": [
    "This notebook is intended to run a model which can predict the emotion of a given track through its lyrics, using the library TensorFlow 2.0 in order to create the Deep Learning process. The model will be finally used in a Data Science Python project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "42upF5GxFplV"
   },
   "source": [
    "First of all, we need to import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1600038238731,
     "user": {
      "displayName": "Alexander Valenzuela",
      "photoUrl": "https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg",
      "userId": "10143828526109492816"
     },
     "user_tz": 180
    },
    "id": "0POhnUvMENtx"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from google.colab import files\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CoOWf14NGHeD"
   },
   "source": [
    "The next step is loading the parameters of the model which are stored in a json file named `parameters.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1600038239955,
     "user": {
      "displayName": "Alexander Valenzuela",
      "photoUrl": "https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg",
      "userId": "10143828526109492816"
     },
     "user_tz": 180
    },
    "id": "Oy-jhhOnGEYg"
   },
   "outputs": [],
   "source": [
    "with open('parameters.json', 'r') as json_file:\n",
    "    pm = json.load(json_file)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g4vabJZtHKHr"
   },
   "source": [
    "The first part of a training model is loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1600038241700,
     "user": {
      "displayName": "Alexander Valenzuela",
      "photoUrl": "https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg",
      "userId": "10143828526109492816"
     },
     "user_tz": 180
    },
    "id": "wUqke9eQHKog"
   },
   "outputs": [],
   "source": [
    "lyrics = []  # Here will be stored the lyrics data\n",
    "emotions = []  # Here will be stored the emotions data\n",
    "\n",
    "# Here will be stored every type of emotiom\n",
    "labels = [\"Anger\", \"Joy\", \"Sad\", \"Disgusting\", \"Fear\", \"Suprise\"]\n",
    "\n",
    "data_path = os.path.join('data', 'lyrics_dataset.csv')\n",
    "\n",
    "def loading_data(lyrics_list, emotions_list, path):\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        dataset = csv.reader(file)\n",
    "        next(dataset)  # We skip the header of the file\n",
    "\n",
    "        for track in dataset:\n",
    "            lyrics_list.append(track[0].capitalize())\n",
    "            emotions_list.append(track[3].capitalize())\n",
    "\n",
    "\n",
    "# We need to numerize the emotions\n",
    "def numerize_emotions(emotions_dataset):\n",
    "    for i in range(len(emotions_dataset)):\n",
    "        for j in range(len(labels)):\n",
    "            if emotions_dataset[i] == labels[j]:\n",
    "                emotions_dataset[i] = j\n",
    "\n",
    "\n",
    "loading_data(lyrics, emotions, data_path)\n",
    "numerize_emotions(emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have enough data, we will split it into training data and testing data, but in order to get the best model accuracy we are going to use the K-Fold Cross Validation, with 5 folds, 10 folds and the sample size minus 1 (\"leave one out\") as recommended in *Big Data: New Tricks for Econometrics, Hal R. Varian, 2013.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(test_size)\n",
    "training_lyrics, training_emotions, testiong_lyrics, training_emotions = train_test_split(\n",
    "    (lyrics, emotions, test_size=test_size))\n",
    "\n",
    "cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsqEvcorH7qX"
   },
   "source": [
    "Once the data is stored in the code, we need to convert the data, which are fragments of lyrics, into numbers because the Deep Learning process only can work with number and vector arrays. This process is known as \"Tokenization\". Fortunately, `tensorflow` provides a `Tokenizer` class which has all the methods needed to tokenize our data. Moreover, the `numpy` library will help us convert the numbers into vector arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1600038243957,
     "user": {
      "displayName": "Alexander Valenzuela",
      "photoUrl": "https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg",
      "userId": "10143828526109492816"
     },
     "user_tz": 180
    },
    "id": "--Pi1WVFH5iR"
   },
   "outputs": [],
   "source": [
    "# Tokenization process\n",
    "tokenizer = Tokenizer(num_words=pm[\"num_words\"], oov_token=pm[\"oov_tok\"])\n",
    "tokenizer.fit_on_texts(training_lyrics)  # Words are fitted on the tokenizer\n",
    "word_index = tokenizer.word_index  # Words are represented by index\n",
    "\n",
    "vocab_size = len(word_index) + 1  # The size of the vocabulary\n",
    "\n",
    "training_lyrics = tokenizer.texts_to_sequences(training_lyrics)\n",
    "training_lyrics = pad_sequences(\n",
    "    training_lyrics,\n",
    "    maxlen=pm[\"max_length\"],\n",
    "    padding=pm[\"padding_type\"],\n",
    "    truncating=pm[\"trunc_type\"]\n",
    ")\n",
    "\n",
    "testing_lyrics = tokenizer.texts_to_sequences(testing_lyrics)\n",
    "testing_lyrics = pad_sequences(\n",
    "    testing_lyrics,\n",
    "    maxlen=pm[\"max_length\"],\n",
    "    padding=pm[\"padding_type\"],\n",
    "    truncating=pm[\"trunc_type\"]\n",
    ")\n",
    "\n",
    "training_emotions = to_categorical(training_emotions, len(labels))\n",
    "testing_emotions = to_categorical(testing_emotions, len(labels))\n",
    "\n",
    "\n",
    "# Transforming the tokenized data in numpy arrays\n",
    "training_lyrics = np.array(training_lyrics)\n",
    "training_emotions = np.array(training_emotions)\n",
    "testing_lyrics = np.array(testing_lyrics)\n",
    "testing_emotions = np.array(testing_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wgvgy2-cK5Oo"
   },
   "source": [
    "Now that the tokenization is done, let's create the model. the `tensorflow` library provides us a `Sequential` class which is used to build Neural Networks (NN). Each layer of our NN system has to be in the correct order, so first we need to create an `Embedding` layer in order to \"vectorize\" each sentense according to the similarity or difference of each input. For more info about how Neural Networks works, there are many information through Internet.\n",
    "\n",
    "Next, the output of this layer will be passed to `LSTM` layers, who will use the information and, in a recurrent loop the model will be trained. Finally, according to the result of each input, the `Dense` layers will help us define the result of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1087,
     "status": "ok",
     "timestamp": 1600038247747,
     "user": {
      "displayName": "Alexander Valenzuela",
      "photoUrl": "https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg",
      "userId": "10143828526109492816"
     },
     "user_tz": 180
    },
    "id": "Sz2jKX81K4Ng"
   },
   "outputs": [],
   "source": [
    "# Generation of the Recurrent Neural Network (RNN)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                              input_length=pm[\"max_length\"],\n",
    "                              output_dim=pm[\"embedding_dim\"]),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.LSTM(pm[\"embedding_dim\"],\n",
    "                         return_sequences=True,\n",
    "                         dropout=0.3,\n",
    "                         recurrent_dropout=0.2),\n",
    "    tf.keras.layers.LSTM(pm[\"embedding_dim\"],\n",
    "                         dropout=0.3,\n",
    "                         recurrent_dropout=0.2),\n",
    "    tf.keras.layers.Dense(len(labels), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eDzqLnwzNLyw"
   },
   "source": [
    "The last step of the training process is ... training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 271754,
     "status": "ok",
     "timestamp": 1600040853349,
     "user": {
      "displayName": "Alexander Valenzuela",
      "photoUrl": "https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg",
      "userId": "10143828526109492816"
     },
     "user_tz": 180
    },
    "id": "Dvt840a4NE9l",
    "outputId": "d44a9201-ec7d-43c3-9402-d4c98de44262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "158/158 - 127s - loss: 1.5894 - accuracy: 0.3075\n",
      "Epoch 2/20\n",
      "158/158 - 127s - loss: 1.5410 - accuracy: 0.3529\n",
      "Epoch 3/20\n",
      "158/158 - 128s - loss: 1.4087 - accuracy: 0.4624\n",
      "Epoch 4/20\n",
      "158/158 - 127s - loss: 1.2761 - accuracy: 0.5202\n",
      "Epoch 5/20\n",
      "158/158 - 127s - loss: 1.1599 - accuracy: 0.5677\n",
      "Epoch 6/20\n",
      "158/158 - 127s - loss: 1.0608 - accuracy: 0.6107\n",
      "Epoch 7/20\n",
      "158/158 - 127s - loss: 0.9354 - accuracy: 0.6570\n",
      "Epoch 8/20\n",
      "158/158 - 128s - loss: 0.8378 - accuracy: 0.6962\n",
      "Epoch 9/20\n",
      "158/158 - 129s - loss: 0.7515 - accuracy: 0.7339\n",
      "Epoch 10/20\n",
      "158/158 - 128s - loss: 0.6781 - accuracy: 0.7564\n",
      "Epoch 11/20\n",
      "158/158 - 127s - loss: 0.7656 - accuracy: 0.7297\n",
      "Epoch 12/20\n",
      "158/158 - 127s - loss: 0.6391 - accuracy: 0.7717\n",
      "Epoch 13/20\n",
      "158/158 - 129s - loss: 0.5628 - accuracy: 0.8083\n",
      "Epoch 14/20\n",
      "158/158 - 129s - loss: 0.5061 - accuracy: 0.8356\n",
      "Epoch 15/20\n",
      "158/158 - 128s - loss: 0.4537 - accuracy: 0.8529\n",
      "Epoch 16/20\n",
      "158/158 - 129s - loss: 0.4011 - accuracy: 0.8723\n",
      "Epoch 17/20\n",
      "158/158 - 130s - loss: 0.3590 - accuracy: 0.8830\n",
      "Epoch 18/20\n",
      "158/158 - 135s - loss: 0.3274 - accuracy: 0.8984\n",
      "Epoch 19/20\n",
      "158/158 - 130s - loss: 0.2917 - accuracy: 0.9137\n",
      "Epoch 20/20\n",
      "158/158 - 131s - loss: 0.2725 - accuracy: 0.9135\n",
      "95/95 [==============================] - 12s 124ms/step - loss: 0.1628 - accuracy: 0.9555\n",
      "[0.16278034448623657, 0.9554669260978699]\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_lyrics,\n",
    "    training_emotions,\n",
    "    epochs=pm[\"num_epochs\"],\n",
    "    batch_size=32,\n",
    "    verbose=2\n",
    ")\n",
    "results = model.evaluate(testing_lyrics, testing_emotions)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FR-LK7cZNhIz"
   },
   "source": [
    "¡We have reached **95.54%** of accuracy!\n",
    "\n",
    "The following code is written in order to store in the local machine the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 725,
     "status": "ok",
     "timestamp": 1600041475149,
     "user": {
      "displayName": "Alexander Valenzuela",
      "photoUrl": "https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg",
      "userId": "10143828526109492816"
     },
     "user_tz": 180
    },
    "id": "w4jVZ6uyQ5-7"
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5GkPUjJsNnZD"
   },
   "source": [
    "Now, once the training and testing process are done, we can predict emotions with new information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1778,
     "status": "ok",
     "timestamp": 1600041505420,
     "user": {
      "displayName": "Alexander Valenzuela",
      "photoUrl": "https://lh5.googleusercontent.com/-CqSaqDsADVg/AAAAAAAAAAI/AAAAAAAAD40/QEFvKyMF4HQ/s64/photo.jpg",
      "userId": "10143828526109492816"
     },
     "user_tz": 180
    },
    "id": "BxqcN7NbNgdF",
    "outputId": "4663b332-6dcc-4c54-e5cd-75b572b6438d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb398d44ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Anger: 0.0004190314\n",
      "Joy: 0.99541414\n",
      "Sad: 0.00065330206\n",
      "Disgusting: 0.00026164335\n",
      "Fear: 0.00024047188\n",
      "Suprise: 0.0030113417\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h5')\n",
    "\n",
    "phrase = [\"'Cause you're amazing just the way you are\"] # Here the lyrics can be predicted\n",
    "sequence = tokenizer.texts_to_sequences(phrase)\n",
    "padded = pad_sequences(sequence,\n",
    "                       maxlen=pm[\"max_length\"],\n",
    "                       padding=pm[\"padding_type\"],\n",
    "                       truncating=pm[\"trunc_type\"])\n",
    "results = model.predict(padded)\n",
    "for i in range(len(labels)):\n",
    "    print(labels[i] + \":\", results[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPr5gbl2apw4xHxEbXYy4kK",
   "collapsed_sections": [],
   "name": "sentiment_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
